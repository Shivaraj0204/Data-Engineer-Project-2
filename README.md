**Project Overview**
This project showcases the utilization of various technologies for orchestrating and managing a data pipeline efficiently.

**Technologies Used**
Apache Airflow: Airflow is employed for orchestrating and managing the data pipeline. It facilitates the scheduling, monitoring, and management of workflows.

AWS EMR (Elastic MapReduce): EMR is utilized for performing heavy data processing tasks. It provides a scalable and cost-effective solution for processing large datasets using Apache Hadoop, Apache Spark, and other open-source frameworks.

**Project Highlights**
Airflow Integration with EMR: Airflow is integrated with AWS EMR to create and manage EMR clusters dynamically. This allows for seamless scaling based on workload demands and ensures efficient resource utilization.

Cost Optimization with Airflow: Airflow is leveraged to automate the creation and termination of EMR clusters. Clusters are spun up only when required for processing, and then terminated afterward to save on costs.
